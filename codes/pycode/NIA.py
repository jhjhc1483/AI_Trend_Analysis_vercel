import requests
from bs4 import BeautifulSoup
import pandas as pd
import os
import json
import re
# =============================================================
# ì…€ 4: NIA ì›¹ í¬ë¡¤ë§ ë° ë°ì´í„° ìˆ˜ì§‘ ë¡œì§
# =============================================================

# NIA ë©”ì¸ í˜ì´ì§€ì— ì˜¬ë¼ì˜¨ ìµœì‹  5ê°€ì§€ë§Œ í¬ë¡¤ë§
response = requests.get("https://nia.or.kr/site/nia_kor/main.do;jsessionid=6EACE24EADAB8A749EFCC1293267C284.33f82d3a14ca06361270")
html = response.text
soup = BeautifulSoup(html, 'html.parser')

data = []
items=soup.select(".article.know")

for i in range(1, 6):
    try:
        selector_base = f".article.know > ul > li:nth-child({i}) > a"
        name = soup.select_one(selector_base).attrs['title']
        name = name.rstrip('}')
        category = soup.select_one(f"{selector_base} > span.category").text
        code0 = soup.select_one(selector_base).attrs['onclick']
        
        pattern = re.compile(r"'([^']*)'")
        raw_arguments = pattern.findall(code0)
        extracted_numbers = [arg for arg in raw_arguments if arg.isdigit()]
        
        code1 = extracted_numbers[0]
        code2 = extracted_numbers[1]
        code3 = extracted_numbers[2]
        link = f'https://nia.or.kr/site/nia_kor/ex/bbs/View.do?cbIdx={code1}&bcIdx={code2}&parentSeq={code3}'
        
        response = requests.get(link)
        html3 = response.text
        soup3 = BeautifulSoup(html3, 'html.parser')
        
        html_string = soup3.select_one(".src>em").text
        date_parts = html_string.split('.')
        year = date_parts[0]
        month = date_parts[1]
        day = date_parts[2]
        
        data.append([name, category, link, year, month, day])
        
    except AttributeError as e:
        print(f"í•­ëª© {i} ì²˜ë¦¬ ì¤‘ ì…€ë ‰í„° ì˜¤ë¥˜ ë°œìƒ: {e}")
    except IndexError as e:
        print(f"í•­ëª© {i} ì²˜ë¦¬ ì¤‘ ì¸ì ì¶”ì¶œ ì˜¤ë¥˜ ë°œìƒ: {e}")
    except Exception as e:
        print(f"í•­ëª© {i} ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")


# =============================================================
# ì…€ 5: DataFrame ìƒì„± ë° ì¶œë ¥
# =============================================================
df3 = pd.DataFrame(data, columns=['ì œëª©', 'ë¶„ë¥˜', 'ë§í¬', 'ë…„', 'ì›”', 'ì¼'])


# =============================================================
# ì…€ 6: JSON íŒŒì¼ ì´ì–´ ë¶™ì´ê¸° ë° ì €ì¥ ë¡œì§ (ê²½ë¡œ ìˆ˜ì •ë¨)
# =============================================================

# ğŸ’¡ í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ë””ë ‰í† ë¦¬(code í´ë”)ì— ì €ì¥ë©ë‹ˆë‹¤.
full_path = 'codes/nia.json' 
new_data = df3.to_dict('records')

existing_data = []

# 1. ê¸°ì¡´ JSON íŒŒì¼ ë¡œë“œ
if os.path.exists(full_path):
    try:
        with open(full_path, 'r', encoding='utf-8') as f:
            content = f.read()
            if content:
                existing_data = json.loads(content)
            else:
                print("ê¸°ì¡´ JSON íŒŒì¼ì€ ì¡´ì¬í•˜ì§€ë§Œ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ìƒˆ ë°ì´í„°ë§Œ ì €ì¥í•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"ê¸°ì¡´ JSON íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({e}). ìƒˆ ë°ì´í„°ë§Œ ì €ì¥í•©ë‹ˆë‹¤.")
        existing_data = []

# 2. ìƒˆ ë°ì´í„°ì™€ ê¸°ì¡´ ë°ì´í„°ë¥¼ í•©ì¹˜ê¸°
combined_data = existing_data + new_data

# 3. ì¤‘ë³µ ì œê±°
seen_links = set()
final_data = []

for item in combined_data:
    link = item.get('ë§í¬')
    if link and link not in seen_links:
        final_data.append(item)
        seen_links.add(link)
        
print(f"ì´ {len(existing_data)}ê°œì˜ ê¸°ì¡´ ë°ì´í„°ì™€ {len(new_data)}ê°œì˜ ìƒˆ ë°ì´í„°ë¥¼ í•©ì³¤ìŠµë‹ˆë‹¤.")
print(f"ì¤‘ë³µì„ ì œê±°í•œ í›„ ìµœì¢… ë°ì´í„°ëŠ” ì´ {len(final_data)}ê°œì…ë‹ˆë‹¤.")

# 4. ìµœì¢… ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
with open(full_path, 'w', encoding='utf-8') as f:
    json.dump(final_data, f, indent=4, ensure_ascii=False)

print(f"\nìµœì¢… ë°ì´í„°ê°€ '{full_path}'ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

