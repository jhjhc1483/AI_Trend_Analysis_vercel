from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import time
import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
import os
import json

# 1. WebDriver ì˜µì…˜ ì„¤ì •
chrome_options = Options()

# ğŸ’¡ í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ í™œì„±í™”
chrome_options.add_argument("--headless=new")
# ë¶ˆí•„ìš”í•œ ì—ëŸ¬ ë©”ì‹œì§€ ì—†ì• ê¸°
chrome_options.add_experimental_option("excludeSwitches", ["enable-logging"])
# ê¸°íƒ€ í—¤ë“œë¦¬ìŠ¤ í™˜ê²½ ìµœì í™” ì˜µì…˜
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
# # ì°½ í¬ê¸° ì„¤ì •
chrome_options.add_argument("window-size=1920x1080") 

# 2. Service ê°ì²´ ìƒì„± ë° WebDriver ì´ˆê¸°í™”
service = Service(executable_path=ChromeDriverManager().install())

try:
    # 3. WebDriver ì´ˆê¸°í™”
    browser = webdriver.Chrome(service=service, options=chrome_options)
    
    browser.get('https://www.aitimes.com/news/articleList.html?page=1&total=29543&sc_section_code=&sc_sub_section_code=&sc_serial_code=&sc_area=&sc_level=&sc_article_type=&sc_view_level=&sc_sdate=&sc_edate=&sc_serial_number=&sc_word=&sc_andor=&sc_word2=&box_idxno=&sc_multi_code=&sc_is_image=&sc_is_movie=&sc_user_name=&sc_order_by=E')
    browser.implicitly_wait(10) # ë¬µì‹œì  ëŒ€ê¸° ì‹œê°„ ì„¤ì •
    more_button = browser.find_element(By.CSS_SELECTOR, '#section-list > button')
    
    more_button.click()
    more_button.click()
    more_button.click()
    more_button.click()

    items = browser.find_elements(By.CSS_SELECTOR, '.altlist-text-item')
    data = []
    
    print(f"ì´ {len(items)}ê°œì˜ ê¸°ì‚¬ í•­ëª©ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    for item in items:
        try:
            name = item.find_element(By.CSS_SELECTOR, '.altlist-subject').text
            link_element = item.find_element(By.CSS_SELECTOR, '.altlist-subject > a')
            link = link_element.get_attribute('href')
            
            if not link:
                print(f"ê²½ê³ : ë§í¬ê°€ ë¹„ì–´ìˆëŠ” í•­ëª©ì„ ê±´ë„ˆëœë‹ˆë‹¤. (ê¸°ì‚¬ëª…: {name})")
                continue
        
            response = requests.get(link)
            response.raise_for_status()
            html = response.text
            soup = BeautifulSoup(html, 'html.parser')
            
            date_text = soup.select_one(".breadcrumbs > li:nth-child(2)").text.strip()
            match = re.search(r'(\d{4})\.(\d{2})\.(\d{2})\s(\d{2}):(\d{2})', date_text)
            
            if match:
                years, month, day, hour, minute = match.groups()
            else:
                print(f"ê²½ê³ : ë‚ ì§œ/ì‹œê°„ í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë§í¬: {link})")
                years, month, day, hour, minute = 'N/A', 'N/A', 'N/A', 'N/A', 'N/A'

            data.append([name, link, years, month, day, hour, minute])
            
        except Exception as e:
            print(f"ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë§í¬: {link if 'link' in locals() else 'N/A'}): {e}")
            continue

    browser.quit()

    df1 = pd.DataFrame(data, columns=['ê¸°ì‚¬ëª…','ë§í¬','ë…„','ì›”','ì¼','ì‹œ','ë¶„'])
    df1['ê¸°ì‚¬ëª…'] = df1['ê¸°ì‚¬ëª…'].fillna('')
    df1['ê¸°ì‚¬ëª…'] = df1['ê¸°ì‚¬ëª…'].str.replace('\\', '', regex=False)
    df1['ê¸°ì‚¬ëª…'] = df1['ê¸°ì‚¬ëª…'].str.replace('\'', 'ï¼‡', regex=False)
    df1['ê¸°ì‚¬ëª…'] = df1['ê¸°ì‚¬ëª…'].str.replace('\"', 'ã€ƒ', regex=False)


    full_path = 'codes/aitimes.json' 
    new_data = df1.to_dict('records')

    existing_data_dict = {}
    total_existing = 0
    total_new = len(new_data)
    update_count = 0
    skip_count = 0

    # 1. ê¸°ì¡´ JSON íŒŒì¼ ë¡œë“œ ë° ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (linkë¥¼ í‚¤ë¡œ ì‚¬ìš©)
    if os.path.exists(full_path):
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                content = f.read()
                if content:
                    existing_list = json.loads(content)
                    total_existing = len(existing_list)
               
                    for item in existing_list:
                        link = item.get('ë§í¬')
                        if link:
                            existing_data_dict[link] = item
                else:
                    print("ê¸°ì¡´ JSON íŒŒì¼ì€ ì¡´ì¬í•˜ì§€ë§Œ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ê¸°ì¡´ JSON íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({e}). ìƒˆ ë°ì´í„°ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            existing_data_dict = {}

    # 2. ìƒˆ ë°ì´í„°ë¥¼ ìˆœíšŒí•˜ë©° ì—…ë°ì´íŠ¸ ë˜ëŠ” ìŠ¤í‚µ ê²°ì •
    for item in new_data:
        link = item.get('ë§í¬')

        new_time_tuple = (item.get('ë…„'), item.get('ì›”'), item.get('ì¼'), item.get('ì‹œ'), item.get('ë¶„'))

        if link in existing_data_dict:

            existing_item = existing_data_dict[link]
            existing_time_tuple = (existing_item.get('ë…„'), existing_item.get('ì›”'), existing_item.get('ì¼'), existing_item.get('ì‹œ'), existing_item.get('ë¶„'))
            if new_time_tuple != existing_time_tuple:
                existing_data_dict[link] = item # ë®ì–´ì“°ê¸°
                update_count += 1
            else:
                skip_count += 1
        else:

            existing_data_dict[link] = item

    # 3. ë”•ì…”ë„ˆë¦¬ ê°’ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ìµœì¢… ë°ì´í„° ì¤€ë¹„
    final_data = list(existing_data_dict.values())
            
    print(f"\n--- ë°ì´í„° ì €ì¥ ìš”ì•½ ---")
    print(f"ì´ {total_existing}ê°œì˜ ê¸°ì¡´ ë°ì´í„°ì™€ {total_new}ê°œì˜ ìƒˆ ë°ì´í„°ë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
    print(f" - **ì—…ë°ì´íŠ¸(ì‹œê°„ ë³€ê²½)**ëœ í•­ëª©: {update_count}ê°œ")
    print(f" - **ì¤‘ë³µ(ë§í¬+ì‹œê°„ ë™ì¼)**ë˜ì–´ ìŠ¤í‚µëœ í•­ëª©: {skip_count}ê°œ")
    print(f" - **ìƒˆë¡œ ì¶”ê°€**ëœ í•­ëª©: {len(final_data) - total_existing + skip_count}ê°œ") # ìƒˆë¡œ ì¶”ê°€ = ìµœì¢… - ê¸°ì¡´ + ìŠ¤í‚µ
    print(f"ì¤‘ë³µì„ ì œê±° ë° ì—…ë°ì´íŠ¸í•œ í›„ ìµœì¢… ë°ì´í„°ëŠ” ì´ {len(final_data)}ê°œì…ë‹ˆë‹¤.")

    # 4. ìµœì¢… ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    os.makedirs(os.path.dirname(full_path), exist_ok=True)
    with open(full_path, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, indent=4, ensure_ascii=False)

    print(f"ìµœì¢… ë°ì´í„°ê°€ '{full_path}'ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

except Exception as e:
    print(f"í¬ë¡¤ë§/ìŠ¤í¬ë˜í•‘ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
    if 'browser' in locals():
        browser.quit()
